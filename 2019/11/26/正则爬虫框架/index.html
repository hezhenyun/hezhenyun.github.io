<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style-dark.css?v=2.0.4"><link rel="stylesheet" type="text/css" href="/css/highlight-dark.css?v=2.0.4"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.4"><title>利用正则和爬虫知识爬取网站 | 浮生醉清风</title><meta name="generator" content="Hexo 4.0.0"><link rel="alternate" href="/atom.xml" title="浮生醉清风" type="application/atom+xml">
</head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">利用正则和爬虫知识爬取网站</h1><a id="logo" href="/.">浮生醉清风</a><p class="description">没有比脚更长的路，走过去，前面是个天！</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">利用正则和爬虫知识爬取网站</h1><div class="post-meta"><a href="/2019/11/26/%E6%AD%A3%E5%88%99%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/#comments" class="comment-count"></a><p><span class="date">Nov 26, 2019</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>以下是自己在学习爬虫时，利用正则和爬虫知识爬取豆瓣电影排行榜的一些总结，仅供参考，如有不足，还请关照</p>
<h2 id="1-请求"><a href="#1-请求" class="headerlink" title="1.请求"></a>1.请求</h2><pre><code>在爬取网站是，首先就是先要发送自己的请求，看能不能访问到此网站，在这，我便以爬取豆瓣电影排行榜为例。</code></pre><p>在向豆瓣网站发送请求时，要添加一下自定义的headers,如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$  headers = &#123;</span><br><span class="line">$            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/\</span></span><br><span class="line"><span class="string">$                    537.36 (KHTML, like Gecko) Chrome/\</span></span><br><span class="line"><span class="string">$                    78.0.3904.70 Safari/537.36'</span></span><br><span class="line">$        &#125;</span><br></pre></td></tr></table></figure>




<p>在这里发送请求我用的是Requests,对于接触过爬虫的都会了解这个，我便不多说了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ response = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>

<p>这里的url指的就是所要爬取的网站的网址。</p>
<p>下面是一个完整的请求，用一个函数来概括。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$	def get__one__page(url):</span><br><span class="line">$		try:</span><br><span class="line">$			headers = &#123;</span><br><span class="line">$				<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/\</span></span><br><span class="line"><span class="string">$						537.36 (KHTML, like Gecko) Chrome/\</span></span><br><span class="line"><span class="string">$						78.0.3904.70 Safari/537.36'</span></span><br><span class="line">$			&#125;</span><br><span class="line">$			response = requests.get(url, headers=headers)</span><br><span class="line">$			<span class="keyword">if</span> response.status_code == 200:</span><br><span class="line">$				<span class="built_in">return</span> response.text</span><br><span class="line">$			<span class="built_in">return</span> None</span><br><span class="line">$		except RequestException:</span><br><span class="line">$			<span class="built_in">return</span> None</span><br><span class="line">$</span><br></pre></td></tr></table></figure>
<p>在这里我用的是返回的响应码来做一个判断，当请求成功是返回的就是200，错误就会直接返回None,这里运用了一个异常判断来处理</p>
<h2 id="2-解析"><a href="#2-解析" class="headerlink" title="2.解析"></a>2.解析</h2><p>在请求成功后，会返回对应网址的一些代码信息，这里就需要去解析这些代码信息，整理出来我们所需要的的数据信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$	def parse__one__page(html):</span><br><span class="line">$		pattern = re.compile(</span><br><span class="line">$			    <span class="string">'&lt;li&gt;.*?class=""&gt;(\d+)&lt;.*?src="(.*?)".*?&gt;.*?title"&gt;(.*?)&lt;.*?&gt;.*?&lt;p.*?&gt;(.*?)&lt;br&gt;.*?&lt;/p&gt;.*?average"&gt;(.*?)&lt;.*?&lt;/li&gt;'</span>,</span><br><span class="line">$			re.S)</span><br><span class="line">$</span><br><span class="line">$		items = re.findall(pattern, html)</span><br><span class="line">$		<span class="comment"># print(items)</span></span><br><span class="line">$		<span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">$			yield &#123;</span><br><span class="line">$				<span class="string">'index'</span>: item[0],</span><br><span class="line">$				<span class="string">'image'</span>: item[1],</span><br><span class="line">$				<span class="string">'title'</span>: item[2],</span><br><span class="line">$				<span class="string">'director'</span>: item[3],</span><br><span class="line">$				<span class="string">'score'</span>: item[4]</span><br><span class="line">$			&#125;</span><br></pre></td></tr></table></figure>
<p>以上解析用的是正则表达式的知识来进行的，（如果对正则知识不熟练的可以参考我的另一篇文章），利用正则解析过，能够得到我们想要的信息后，会感觉还是比较乱，那么就要用到for循环迭代器了，进行有序的输出，使自己想要的数据信息更加清楚明白。</p>
<h2 id="3-读入文件中"><a href="#3-读入文件中" class="headerlink" title="3.读入文件中"></a>3.读入文件中</h2><p>在以上我们得到自己想要的信息后就要存放到本地的文件中，便于自己的浏览和使用，所以就要用到文件的知识了，这里就不多说了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$	def write__one__page(content):</span><br><span class="line">$		with open(<span class="string">'result.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) as f:</span><br><span class="line">$			f.write(json.dumps(content, ensure_ascii=False))</span><br><span class="line">$			f.write(<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<p>读入文件后，打开本地的文本文件，就可以显示了，好了就到这了。</p>
<h2 id="主代码"><a href="#主代码" class="headerlink" title="主代码"></a>主代码</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$	def main(number):</span><br><span class="line">$		url = <span class="string">'https://movie.douban.com/top250?start='</span> + number + <span class="string">'&amp;filter='</span> + str(number)</span><br><span class="line">$		html = get__one__page(url)</span><br><span class="line">$		<span class="comment"># parse__one__page(html)</span></span><br><span class="line">$		<span class="comment"># print(html)</span></span><br><span class="line">$		<span class="keyword">for</span> item <span class="keyword">in</span> parse__one__page(html):</span><br><span class="line">$			<span class="built_in">print</span>(item)</span><br><span class="line">$			write__one__page(item)</span><br><span class="line">$</span><br><span class="line">$</span><br><span class="line">$	<span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">$		<span class="keyword">for</span> i <span class="keyword">in</span> range(10):</span><br><span class="line">$			main(number=str(i * 25))</span><br><span class="line">$			time.sleep(1)</span><br><span class="line">$		<span class="comment"># main()</span></span><br></pre></td></tr></table></figure>

<h2 id="阐述"><a href="#阐述" class="headerlink" title="阐述"></a>阐述</h2><p>以上仅是自我的总结，仅供参考。</p>
</div><div class="post-copyright"><blockquote><p>原文作者: 何阵运(HE)</p><p>原文链接: <a href="http://yoursite.com/2019/11/26/正则爬虫框架/">http://yoursite.com/2019/11/26/正则爬虫框架/</a></p><p>版权声明: 转载请注明出处(必须保留作者署名及链接)</p></blockquote></div><div class="tags"></div><div class="post-share"><div class="social-share"><span>分享到:</span></div></div><div class="post-nav"><a href="/2019/11/28/xpath/" class="pre">xpath语法</a><a href="/2019/11/24/requests%E7%9A%84%E7%94%A8%E6%B3%95/" class="next">Requests的基本用法</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.4"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.4"></script><script>var gitalk = new Gitalk({
  clientID: '85fb83e0b8b61db58f67',
  clientSecret: 'b6160c94305dc79d2b397318c11305ae5203e792',
  repo: 'hezhenyun.github.io',
  owner: 'hezhenyun',
  admin: ['hezhenyun'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-请求"><span class="toc-text">1.请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-解析"><span class="toc-text">2.解析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-读入文件中"><span class="toc-text">3.读入文件中</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主代码"><span class="toc-text">主代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#阐述"><span class="toc-text">阐述</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/12/04/os%E6%A8%A1%E5%9D%97/">爬虫中储存到文件夹的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/02/strip%E6%96%B9%E6%B3%95/">python strip()方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/30/bs4/">Beautiful Soup基础</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/28/xpath/">xpath语法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/26/%E6%AD%A3%E5%88%99%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/">利用正则和爬虫知识爬取网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/24/requests%E7%9A%84%E7%94%A8%E6%B3%95/">Requests的基本用法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/22/python%E7%89%88%E6%9C%AC/">Python2.x与3​​.x版本区别</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/20/%E7%88%AC%E8%99%AB%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/">python爬虫基本原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/18/python%E6%AD%A3%E5%88%99/">正则表达式之python系列</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/16/hexo%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">使用hexo+github搭建免费博客教程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/%E7%88%AC%E8%99%AB/" style="font-size: 15px;">爬虫</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E5%91%BD%E4%BB%A4/" style="font-size: 15px;">命令</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/Mysql/" style="font-size: 15px;">Mysql</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/CMD/" style="font-size: 15px;">CMD</a> <a href="/tags/requests/" style="font-size: 15px;">requests</a> <a href="/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" style="font-size: 15px;">正则表达式</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">15</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://www.baidu.com" title="百度" target="_blank">百度</a><ul></ul><a href="http://www.google.com/" title="谷歌" target="_blank">谷歌</a><ul></ul><a href="https://github.com/hezhenyun/hezhenyun.github.io.git" title="My github" target="_blank">My github</a><ul></ul><a href="https://weibo.com/u/5792236259" title="我的微博" target="_blank">我的微博</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">何阵运(HE).</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.4"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.4" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script></body></html>